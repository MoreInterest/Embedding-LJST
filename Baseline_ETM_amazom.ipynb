{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "from scipy import spatial\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.special import gammaln\n",
    "from collections import Counter\n",
    "\n",
    "import imp\n",
    "import datetime\n",
    "import LDA_ETM as lda\n",
    "import scipy\n",
    "import operator\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import utils as my_utils\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"amazon_musical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"datasets/datadf_amazon_musical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "      <td>[much, write, doe, exactly, supposed, filter, ...</td>\n",
       "      <td>much write doe exactly supposed filter pop sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "      <td>[product, doe, exactly, quite, affordable, rea...</td>\n",
       "      <td>product doe exactly quite affordable realized ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "\n",
       "                                          reviewText  sentiment summary  \\\n",
       "0  Not much to write about here, but it does exac...        5.0    good   \n",
       "1  The product does exactly as it should and is q...        5.0    Jake   \n",
       "\n",
       "   unixReviewTime   reviewTime  \\\n",
       "0      1393545600  02 28, 2014   \n",
       "1      1363392000  03 16, 2013   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  [much, write, doe, exactly, supposed, filter, ...   \n",
       "1  [product, doe, exactly, quite, affordable, rea...   \n",
       "\n",
       "                                                text  \n",
       "0  much write doe exactly supposed filter pop sou...  \n",
       "1  product doe exactly quite affordable realized ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix, tfidf_matrix, vocabulary, words = my_utils.processReviews(dataset['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "barren = np.where(count_matrix.sum(1)==0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Edge_Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'amazon_musical'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"resources/edges_amazon_musical_fasttext_nontrained.pickle\",\"rb\")\n",
    "docs_edges = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_edges = np.delete(docs_edges, barren).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10254"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_dict = []\n",
    "for doc in docs_edges:\n",
    "    edge_dict_ = {}\n",
    "    for i, j in doc:\n",
    "        try:\n",
    "            edge_dict_[i] += [j]\n",
    "        except:\n",
    "            edge_dict_[i] = [j]\n",
    "        try:\n",
    "            edge_dict_[j] += [i]\n",
    "        except:\n",
    "            edge_dict_[j] = [i]\n",
    "    edge_dict.append(edge_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_param = 1.0\n",
    "n_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_grid = [5, 10, 15, 20, 30, 40, 60, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"baseline_etm_amazon_musical_fasttext_nontrained_50iter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = str(datetime.datetime.now()) + \"_\" + folder_name\n",
    "os.mkdir(\"dumps/\"+folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiprocessing_func(k):\n",
    "    print \"Started Sampler...\", k\n",
    "    sampler = lda.LdaSampler(n_topics=k, lambda_param=lambda_param)\n",
    "    \n",
    "    sampler.run(count_matrix, edge_dict, maxiter=50)\n",
    "    joblib.dump(sampler, \"dumps/\" + folder_name + \"/sampler_n_topics_\" + str(k))\n",
    "    print \"Done Sampler...\", k\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Sampler... 60\n",
      "Started Sampler... 40\n",
      "Started Sampler... 30\n",
      "Started Sampler... 5\n",
      "Started Sampler... 100\n",
      "Started Sampler... 20\n",
      "Started Sampler... 15\n",
      "Started Sampler... 10\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.map(multiprocessing_func, topics_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"2019-09-14 17:16:20.085880_baseline_etm_amazon_musical_fasttext_nontrained_50iter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder_name = \"2019-09-14 16:11:52.593802_baseline_etm_amazon_musical_fasttext_nontrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def multiprocessing_func_eval(k):\n",
    "    sampler = joblib.load(\"dumps/\"+folder_name + \"/sampler_n_topics_\" + str(k))\n",
    "\n",
    "    t_words = sampler.getTopKWords(n_top_words, words)\n",
    "    top_words = [t_words[i] for i in t_words.keys()]\n",
    "    dt_distribution = sampler.theta()\n",
    "    \n",
    "#     print \"\"\n",
    "#     print \"Topics:\", k\n",
    "#     print \"Coherance:\", my_utils.coherence_score(count_matrix, top_words, vocabulary)\n",
    "#     print \"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     print \"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "\n",
    "    print my_utils.coherence_score(count_matrix, top_words, vocabulary), \"\\t\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)), \"\\t\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics_grid = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.540125146606954 \t-0.03961432428768909 \t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william18026/miniconda3/envs/python2/lib/python2.7/site-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.756703862911031\n",
      "-14.131763524290955 \t-0.049593618152886286 \t10.423438226007871\n",
      "-14.705150297680039 \t-0.10310896601639405 \t10.62825193313079\n",
      "-15.099200770795168 \t-0.08206065236784289 \t10.44437956157738\n",
      "-15.984123197610034 \t-0.09433115422003133 \t10.150427729950685\n",
      "-16.542917388278983 \t-0.1145657841871095 \t9.891144697181995\n",
      "-17.189850187352327 \t-0.12364506388797508 \t8.901109606906713\n",
      "-18.14187090400746 \t-0.12338512674400309 \t8.37448182532487\n"
     ]
    }
   ],
   "source": [
    "for k in topics_grid:\n",
    "    multiprocessing_func_eval(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_dist = sampler.theta()\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_dist)\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_dist.argmax(axis=1))\n",
    "# plt.legend(loc=2)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
