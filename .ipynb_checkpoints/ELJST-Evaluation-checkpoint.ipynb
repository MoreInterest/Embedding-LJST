{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial, sparse\n",
    "from scipy.stats import chi2\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.externals import joblib \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import os\n",
    "import imp\n",
    "import gzip\n",
    "import copy\n",
    "import nltk\n",
    "import pickle\n",
    "import scipy\n",
    "import string\n",
    "import gensim\n",
    "import operator\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import LDA_ILJST_no_test as lda\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as my_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"2019-08-22 00:42:59.099534_stackoverflow_fasttext_with_stopwords\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumps = ['/sampler_stackoverflow_fasttext_with_stopwords_n_topics_10_maxiter_20_iter_5_in_5',\n",
    "        '/sampler_stackoverflow_fasttext_with_stopwords_n_topics_5_maxiter_20_iter_5_in_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(file_):\n",
    "    sampler = joblib.load('dumps/' + folder_name + file_)\n",
    "    top_words = [i[1] for i in sampler.getTopKWords(5, sampler.words).items()]\n",
    "    dt_distribution = sampler.theta()\n",
    "    count_matrix = sampler.get_count_matrix()\n",
    "    k = dt_distribution.shape[1]\n",
    "    vocabulary = sampler.vocabulary\n",
    "    \n",
    "    print\n",
    "    print \"Topics:\", k\n",
    "    print \"Coherance:\", my_utils.coherence_score(count_matrix, top_words, vocabulary)\n",
    "    print \"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "    print \"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics: 10\n",
      "Coherance: -27.368030262585084\n",
      "Silhouette Score: -0.028977591571735677\n",
      "Davies Bouldin Score: 17.13259293382132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/william18026/.conda/envs/python2/lib/python2.7/site-packages/sklearn/metrics/cluster/unsupervised.py:342: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  score = (intra_dists[:, None] + intra_dists) / centroid_distances\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics: 5\n",
      "Coherance: -26.828590436657347\n",
      "Silhouette Score: -0.005535678757135109\n",
      "Davies Bouldin Score: 16.245220824581242\n"
     ]
    }
   ],
   "source": [
    "for i in dumps:\n",
    "    get_scores(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "def geometric_mean(x):\n",
    "    x = [i for i in x if i!=0]\n",
    "    return scipy.stats.mstats.gmean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, k in zip(dataset_names, topics_grid):\n",
    "\n",
    "#     sampler = joblib.load(\"dumps/\" + folder_name + \"/\" + i)\n",
    "#     data = pd.DataFrame()\n",
    "\n",
    "#     data['text'] = texts\n",
    "#     data['sent'] = ratings\n",
    "\n",
    "#     count_matrix = sampler.get_count_matrix()\n",
    "#     binary_mat = (count_matrix > 0).astype(int)\n",
    "#     word_freq = binary_mat.sum(axis=0)\n",
    "\n",
    "#     df_matrix = np.matmul(binary_mat, np.diag(word_freq))\n",
    "#     df_matrix = df_matrix * 1.0/df_matrix.shape[0]\n",
    "\n",
    "#     document_topic_entropy = scipy.stats.entropy(sampler.theta().transpose())\n",
    "#     data['document_topic_entropy'] = document_topic_entropy\n",
    "\n",
    "#     word_len = count_matrix.sum(axis=1)\n",
    "#     data['word_len'] = word_len\n",
    "\n",
    "#     data['document_popularity'] = np.array([geometric_mean(x) for x in df_matrix.tolist()])\n",
    "\n",
    "#     normalized_dts = sampler.pi() * sampler.theta()[:,:,np.newaxis]\n",
    "#     normalized_dts /= normalized_dts.sum(axis=-1)[:,:,np.newaxis]\n",
    "\n",
    "#     document_topic_sentiment_crossentropy = np.array([[scipy.stats.entropy(j) for j in i] for i in normalized_dts])\n",
    "#     document_ts_entropy_min = document_topic_sentiment_crossentropy.min(axis=1)\n",
    "#     document_ts_entropy_mean = document_topic_sentiment_crossentropy.mean(axis=1)\n",
    "#     document_ts_entropy_var = np.sqrt(document_topic_sentiment_crossentropy.var(axis=1))\n",
    "\n",
    "#     data['document_ts_entropy_mean'] = document_ts_entropy_mean\n",
    "#     data['document_ts_entropy_min'] = document_ts_entropy_min\n",
    "#     data['document_ts_entropy_var'] = document_ts_entropy_var\n",
    "\n",
    "#     data['num_edges'] = [len(i) for i in sampler.docs_edges]\n",
    "\n",
    "#     topic_distances = 1/cosine_similarity(sampler.theta().transpose())\n",
    "#     rao_score = []\n",
    "#     for i in range(sampler.theta().shape[0]):\n",
    "#         temp = np.outer(sampler.theta()[i],sampler.theta()[i]) * topic_distances\n",
    "#         rao_score.append(0.5*temp.sum()+0.5*temp.trace())\n",
    "#     rao_score = np.array(rao_score)\n",
    "\n",
    "#     data['rao'] = rao_score\n",
    "#     data['answererID'] = sampler.answer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     merged = data.merge(dataset, on='answererID', how='inner')\n",
    "\n",
    "#     merged.drop(columns=['text', 'sent', 8]).reset_index().drop(columns=['index']).rename(columns={'Id': 'answererID', 9: 'cleaned_answer'}).to_pickle(\"dumps/\" + folder_name + \"/eval_tests_amazon_QA_pd_topics_\" + str(k), protocol=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python2]",
   "language": "python",
   "name": "conda-env-python2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
