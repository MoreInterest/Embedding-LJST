{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import operator\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "import copy\n",
    "import pickle\n",
    "import datetime\n",
    "import joblib\n",
    "\n",
    "import utils as my_utils\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import multiprocessing\n",
    "from scipy import spatial\n",
    "from collections import Counter\n",
    "from scipy.special import gammaln\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"resources/electronics_glove_random_0.35_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = .35\n",
    "title = \"electronics_glove_random_50k\"\n",
    "\n",
    "min_df = 5\n",
    "max_df = .5\n",
    "max_features = 50000\n",
    "\n",
    "n_cores = 30\n",
    "n_docs = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\",tokenizer=None,preprocessor=None,\n",
    "                             stop_words=\"english\", max_features=max_features,\n",
    "                             max_df=max_df, min_df=min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = vectorizer.fit_transform(dataset.text.tolist()).toarray()\n",
    "words = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict(zip(words,np.arange(len(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_grid = [5, 10, 15, 25, 40, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_multi(k):\n",
    "    model = LatentDirichletAllocation(n_components=k, random_state=100, max_iter=10, n_jobs=n_cores, verbose=0)\n",
    "    model.fit(count_matrix)\n",
    "#     joblib.dump(model, \"dumps/\" + folder_name + \"/sampler_n_topics_\" + str(k))\n",
    "    print(\"done:\", k)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 5\n",
      "done: 10\n",
      "done: 15\n",
      "done: 25\n",
      "done: 40\n",
      "done: 60\n"
     ]
    }
   ],
   "source": [
    "models_dump = []\n",
    "for k in topics_grid:\n",
    "    models_dump.append(fit_model_multi(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K: 5\n",
      "Running Metrics...\n",
      "H Score: 0.20297895852514314\n",
      "Log Likelihood: -3220913.4961886797\n",
      "Perplexity: 1144.0985755591178\n",
      "Coherance Score: -14.933474054956928\n",
      "Silhouette Score: -0.025005600618462548\n",
      "Davies Bouldin Score: 10.985223129933836\n",
      "\n",
      "K: 10\n",
      "Running Metrics...\n",
      "H Score: 0.30427975716286004\n",
      "Log Likelihood: -2530422.08926428\n",
      "Perplexity: 1591.1438919527286\n",
      "Coherance Score: -15.265987629954054\n",
      "Silhouette Score: -0.0738346403400513\n",
      "Davies Bouldin Score: 11.111119260694156\n",
      "\n",
      "K: 15\n",
      "Running Metrics...\n",
      "H Score: 0.35168474161661106\n",
      "Log Likelihood: -2547742.980402375\n",
      "Perplexity: 1673.498584894309\n",
      "Coherance Score: -16.576713005906534\n",
      "Silhouette Score: -0.11371370324662419\n",
      "Davies Bouldin Score: 10.537380277916155\n",
      "\n",
      "K: 25\n",
      "Running Metrics...\n",
      "H Score: 0.4153811644465827\n",
      "Log Likelihood: -2577468.086238364\n",
      "Perplexity: 1824.8876454664792\n",
      "Coherance Score: -16.02266155326091\n",
      "Silhouette Score: -0.11607971782311524\n",
      "Davies Bouldin Score: 10.294885543725893\n",
      "\n",
      "K: 40\n",
      "Running Metrics...\n",
      "H Score: 0.4565509225093341\n",
      "Log Likelihood: -2617003.9682848146\n",
      "Perplexity: 2047.6718378919395\n",
      "Coherance Score: -17.152647930736613\n",
      "Silhouette Score: -0.14823353371848957\n",
      "Davies Bouldin Score: 9.433376001225293\n",
      "\n",
      "K: 60\n",
      "Running Metrics...\n"
     ]
    }
   ],
   "source": [
    "for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "    topic_words = {}\n",
    "    for topic, comp in enumerate(model.components_):\n",
    "        word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "        topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "    sample_df = []\n",
    "    for topic, word in topic_words.items():\n",
    "        sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "    dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "    print(\"\\nK:\", k)\n",
    "    print(\"Running Metrics...\")\n",
    "    print(\"H Score:\", my_utils.get_hscore_multi(dt_distribution, count_matrix, k, 3000))\n",
    "    print(\"Log Likelihood:\", model.score(count_matrix))\n",
    "    print(\"Perplexity:\", model.perplexity(count_matrix))\n",
    "    print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "    print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "    print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "    \n",
    "#     print my_utils.coherence_score(count_matrix, sample_df, vocabulary), \"\\t\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)), \"\\t\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_evaluations_multi(model):\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     h_score =  my_utils.get_hscore_multi(dt_distribution, count_matrix, k)\n",
    "#     likelihood =  model.score(count_matrix)\n",
    "#     perplexity = model.perplexity(count_matrix)\n",
    "#     coherance_score = my_utils.coherence_score(count_matrix, sample_df, vocabulary)\n",
    "#     silhouette = silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     return [h_score, likelihood, perplexity, coherance_score, silhouette]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     print(\"\\nK:\", k)\n",
    "#     print(\"Running Metrics...\")\n",
    "#     print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "#     print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "#     print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"H-Score:\", my_utils.get_hscore(dt_distribution, count_matrix, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_distribution)\n",
    "\n",
    "# X_embedded.shape\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_distribution.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
