{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import operator\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import copy\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "import utils as my_utils\n",
    "\n",
    "import multiprocessing\n",
    "from scipy import spatial\n",
    "from collections import Counter\n",
    "from scipy.special import gammaln\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_pickle(\"datasets/datadf_amazon_musical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2IBPI20UZIR0U</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>cassandra tu \"Yeah, well, that's just like, u...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Not much to write about here, but it does exac...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>good</td>\n",
       "      <td>1393545600</td>\n",
       "      <td>02 28, 2014</td>\n",
       "      <td>[much, write, doe, exactly, supposed, filter, ...</td>\n",
       "      <td>much write doe exactly supposed filter pop sou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A14VAT5EAX3D9S</td>\n",
       "      <td>1384719342</td>\n",
       "      <td>Jake</td>\n",
       "      <td>[13, 14]</td>\n",
       "      <td>The product does exactly as it should and is q...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Jake</td>\n",
       "      <td>1363392000</td>\n",
       "      <td>03 16, 2013</td>\n",
       "      <td>[product, doe, exactly, quite, affordable, rea...</td>\n",
       "      <td>product doe exactly quite affordable realized ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  \\\n",
       "0  A2IBPI20UZIR0U  1384719342   \n",
       "1  A14VAT5EAX3D9S  1384719342   \n",
       "\n",
       "                                       reviewerName   helpful  \\\n",
       "0  cassandra tu \"Yeah, well, that's just like, u...    [0, 0]   \n",
       "1                                              Jake  [13, 14]   \n",
       "\n",
       "                                          reviewText  sentiment summary  \\\n",
       "0  Not much to write about here, but it does exac...        5.0    good   \n",
       "1  The product does exactly as it should and is q...        5.0    Jake   \n",
       "\n",
       "   unixReviewTime   reviewTime  \\\n",
       "0      1393545600  02 28, 2014   \n",
       "1      1363392000  03 16, 2013   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0  [much, write, doe, exactly, supposed, filter, ...   \n",
       "1  [product, doe, exactly, quite, affordable, rea...   \n",
       "\n",
       "                                                text  \n",
       "0  much write doe exactly supposed filter pop sou...  \n",
       "1  product doe exactly quite affordable realized ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10254, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix, tfidf_matrix, vocabulary, words = my_utils.processReviews(dataset['text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_grid = [40, 45, 50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model_multi(k):\n",
    "    model = LatentDirichletAllocation(n_components=k, random_state=100)\n",
    "    model.fit(count_matrix)\n",
    "    print(\"done:\", k)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: 5\n",
      "done: 10\n",
      "done: 40\n",
      "done: 45\n",
      "done: 60\n",
      "done: 50\n"
     ]
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "models_dump = pool.map(fit_model_multi, topics_grid)\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K: 5\n",
      "Running Metrics...\n",
      "Coherance Score: -14.152827361263855\n",
      "\n",
      "K: 10\n",
      "Running Metrics...\n",
      "Coherance Score: -13.841778117894894\n",
      "\n",
      "K: 40\n",
      "Running Metrics...\n",
      "Coherance Score: -17.303930307969264\n",
      "\n",
      "K: 45\n",
      "Running Metrics...\n",
      "Coherance Score: -17.257824214715814\n",
      "\n",
      "K: 50\n",
      "Running Metrics...\n",
      "Coherance Score: -17.5610545865298\n",
      "\n",
      "K: 60\n",
      "Running Metrics...\n",
      "Coherance Score: -17.748357701429146\n"
     ]
    }
   ],
   "source": [
    "for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "    topic_words = {}\n",
    "    for topic, comp in enumerate(model.components_):\n",
    "        word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "        topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "    sample_df = []\n",
    "    for topic, word in topic_words.items():\n",
    "        sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "    dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "    print(\"\\nK:\", k)\n",
    "    print(\"Running Metrics...\")\n",
    "    print(\"H Score:\", my_utils.get_hscore_multi(dt_distribution, count_matrix, k))\n",
    "#     print(\"Log Likelihood:\", model.score(count_matrix))\n",
    "#     print(\"Perplexity:\", model.perplexity(count_matrix))\n",
    "#     print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "#     print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "#     print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_evaluations_multi(model):\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     h_score =  my_utils.get_hscore_multi(dt_distribution, count_matrix, k)\n",
    "#     likelihood =  model.score(count_matrix)\n",
    "#     perplexity = model.perplexity(count_matrix)\n",
    "#     coherance_score = my_utils.coherence_score(count_matrix, sample_df, vocabulary)\n",
    "#     silhouette = silhouette_score(count_matrix, dt_distribution.argmax(axis=1))\n",
    "#     return [h_score, likelihood, perplexity, coherance_score, silhouette]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, model in zip(topics_grid, models_dump):\n",
    "\n",
    "#     topic_words = {}\n",
    "#     for topic, comp in enumerate(model.components_):\n",
    "#         word_idx = np.argsort(comp)[::-1][:n_top_words]\n",
    "#         topic_words[topic] = [words[i] for i in word_idx]\n",
    "\n",
    "#     sample_df = []\n",
    "#     for topic, word in topic_words.items():\n",
    "#         sample_df.append(', '.join(word).split(\", \"))\n",
    "\n",
    "#     dt_distribution = model.transform(count_matrix)\n",
    "\n",
    "#     print(\"\\nK:\", k)\n",
    "#     print(\"Running Metrics...\")\n",
    "#     print(\"Coherance Score:\", my_utils.coherence_score(count_matrix, sample_df, vocabulary))\n",
    "#     print(\"Silhouette Score:\", silhouette_score(count_matrix, dt_distribution.argmax(axis=1)))\n",
    "#     print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Davies Bouldin Score:\", davies_bouldin_score(count_matrix, dt_distribution.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"H-Score:\", my_utils.get_hscore(dt_distribution, count_matrix, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# X_embedded = TSNE(n_components=2).fit_transform(dt_distribution)\n",
    "\n",
    "# X_embedded.shape\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# plt.scatter([i[0] for i in X_embedded], [i[1] for i in X_embedded], c=dt_distribution.argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
